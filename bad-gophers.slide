Bad Gophers: unexpected hurdles programming in Go
Sometimes, you have to fight against your own runtime
23 Oct 2018
Tags: containers,golang,goroutines,programming

Francesco Romani
Senior Software Engineer, Red Hat
fromani {gmail,redhat}
http://github.com/{mojaves,fromanirh}

* whoami
- sweng @ Red Hat (but opinions and mistakes are my own!)
- works daily(-ish): libvirt, kvm, python, golang, kubernetes
- interested in: more golang, containers, kubernetes; lisp
- happy linux user (red hat linux, debian, ubuntu, fedora)

* Talk outline

- part 1: a journey in the container world ...

- part 2: ... leading to unexpected hurdles ...

- part 3: ... and how we can overcome them

.link https://github.com/mojaves/ slides and more: github.com/mojaves

* Containers, containers...

.image images/2017-08-28_HS-Reise_Container_an_Deck_der_HEINRICH_SCHEPERS_%282588%29.jpg _ 600
.caption Container an Deck der HEINRICH SCHEPERS by Eduard47, CC BY-SA 4.0, from Wikimedia Commons

* Dramatis Personae

A *container* is a *Linux* *process* (like bash, firefox, thunderbird...) but
*augmented* with a set of the features of the linux kernel to (re)create a *contained* (!) *process* running a *well-known* *image*.

.image images/Containercrane.jpg _ 500
.caption container crane, container kraan in actie, illustratie is zelf gemaakt, Peter Welleman, CC-BY-SA-3.0, from Wikimedia Commons

* Container Engines

Any tool, or set of tools which can run _container_ _image_
(Synonym: container runtime)

Popular engines:
- docker
- rkt
- cri-o

And what about *Kubernetes*?
- management platform
- requires/runs on top a container runtime (docker, cri-o)

* meet runC (1/2)

.link https://blog.docker.com/2015/06/runC/ runC spawned from the docker codebase around 2015
runC is the de facto standard to run containers
runC cli interface treated as ABI
all the major management engines (possibly _all_) under the hood use runC

- docker itself
- cri-o
- containerd

* meet runC (2/2)

.image images/runc_containerd.png _ 1000
.caption the (simplified) containerd architecture

* how runC works (aka the heavy lifting)

to run a container, you need to setup some key management/containement features of the Linux kernel

- cgroups (possibly using systemd)
- SELinux (set up policy)
- seccomp (ditto)
- capabilities (drop privileges)
- *namespaces*

And with namespaces things turn to be interesting.

* hurdles, when the less expected

.image images/hurdle_on_athletic_track.jpg _ 600
.caption Hurdle on athletic track by Santeri Viinamäki, CC BY-SA 4.0, from Wikimedia Commons

* namespaces?

  
  A namespace wraps a global system resource in an abstraction that
  makes it appear to the processes within the namespace that they have
  their own isolated instance of the global resource.
  
  Changes to the global resource are visible to other processes
  that are members of the namespace, but are invisible to other
  processes.

  
.link http://man7.org/linux/man-pages/man7/namespaces.7.html man (7) namespaces

Tools (*syscalls*):
- clone (2) - with the right flags, create a new namespace
- setns (2) - join an existing namespace
- unshare (2) - create a new namespace for the caller

* namespace nesting

global/default namespace by default - when system boot. Let's call this the "outer" namespace

let's say we have other processes run in different namespaces. Let's call these "inner".

And let's pretend we want to write code which wants to join those inner namespace to do some work

In a long running program (daemon)

* namespace nesting (2)

.image images/pstree.png
.caption simple(st) example of a nested namespace 

* setns

Each container runs in its own namespace(s)
Any container management tool need to move processes into another namespace. Or just enter different namespaces.

It boils down to changing namespaces. We can do that invoking a *sycall*

  setns - reassociate thread with a namespace

*Important*: namespace is a *thread* property


* it seems easy

  func runInsideNS() {
    runtime.LockOSThread()
    defer runtime.UnlockOSThread()

    // we start in hostNs
    netns.Set(containerNs)  // we want to do work here
    defer netns.Set(hostNs) // we need to return here once done
    doStuff()
  }

.link https://groups.google.com/forum/#!topic/golang-nuts/ss1gEOcehjk/discussion turns out it is not: there is a nasty surprise hidden
.link https://www.weave.works/blog/linux-namespaces-and-go-don-t-mix as other people found out
.link https://www.weave.works/blog/linux-namespaces-golang-followup (SPOILER) unless you use go >= 1.10


* go scheduler: the bare minimum concepts

We have our code (functions)

Which run in goroutines (*G*) - lightweight threads

goroutines need a context (*P*) to run - needed by the work-stealing go scheduler

goroutines are multiplexed on operathing system threads (*M*)

Work stealing? - needs at least another talk :)

* go scheduler: the bare minimum concepts - illustrated

.image images/go_scheduler_concepts.png 480 _
.caption the go scheduler concepts in practice - see more at https://morsmachine.dk/go-scheduler

* zooming in the go scheduler

The go scheduler may create new threads


  When an M [OS thread] creates a new G[oroutine], it must ensure that
  there is another M [OS thread] to execute the G[oroutine]
  (if not all M[OS Threads]’s are already busy).
  Similarly, when an M [OS thread] enters syscall, it must ensure that
  there is another M[OS Thread] to execute Go code.

More details:
.link https://golang.org/s/go11sched the GO scheduler design document
.link https://golang.org/src/runtime/proc.go the code itself is heavily commented

: potentially creating a new M when we enter a potentially blocking syscall is straightforward.
: other cases are influenced by the go work-stealing scheduler design, see https://morsmachine.dk/go-scheduler

* what's going on? (1/3)

(in a nutshell:) goroutines (G) are multiplexed by the go scheduler on OS threads (M)

.image images/bug_samens.png _ 800

On linux, the implementation uses the `clone(2)` syscall.

when a goroutine does a blocking syscall, the golang runtime might create a new OS thread before entering or exiting the syscall

* what's going on? (2/3)

goroutines transparently created by the go scheduler
.link https://github.com/golang/go/blob/release-branch.go1.11/src/runtime/os_linux.go#L132 will have the same namespace as parent

.image images/bug_expected.png _ 800

* what's going on? (3/3)

So, if the runtime decided to spawn a new thread when your code was inside the "guest" namespace, the new thread will stay there forever

.image images/bug_actual.png _ 800

And your goroutine can randomly run in an unexpected namespace.

* but what about LockOSThread?

  func runInsideNS() {
    runtime.LockOSThread()
    defer runtime.UnlockOSThread()
    netns.Set(containerNs)
    defer netns.Set(hostNs)
    doStuff()
  }


1. `runInsideNS` will indeed run always on the same goroutine
2. `runInsideNS` restores correctly the namespace
3. *however*, while `runInsideNS` runs, the go scheduler _may_ _create_ _a_ _new_ _OS_ _Thread_!
4. and that thread _will_ _inherit_ _the_ _NS_ _on_ _which_ `runInsideNS` _currently_ _runs_!

TL;DR: namespace "leak" from the thread _implicitely_ created by runtime

* Finding solution(s)

.image images/Spork_Plus.jpg _ 800
.caption plastic spork (plus) By CarbonNYC, CC BY 2.0, via Wikimedia Commons

* The quick fix

Let's just spawn a helper process!

it's effective!

Unfortunately:
- our binary is no longer self contained - sometimes a big deal, sometimes not
- spawning a helper is costly
- the helper will face the very same challenges - maybe use another language for the helper, say C? :)

This may or may not a be a issue for your project. But what if...

* I can't or wan't use helpers!

How does runC solve the namespace issue?
.link https://github.com/opencontainers/runC/tree/master/libcontainer/nsenter enter the nsenter package

Implemented in plain old C :)

.link https://github.com/opencontainers/runC/blob/master/libcontainer/nsenter/README.md Excerpt from the README:

  The nsenter package registers a special init constructor that is called before the Go
  runtime has a chance to boot.

We can learn a few tricks here

* zooming inside runC

We have seen `runC` is the core component of every major (possibly all) container runtime

.link https://github.com/opencontainers/runC/tree/master/libcontainer In turn libcontainer is the core component of runC

libcontainer is pretty tied to runC
This also is a project derived from the Docker sources (~2015)

So, let's look inside libcontainer

* jumping through hoops

.link https://github.com/opencontainers/runC/blob/master/libcontainer/README.md From the README of libcontainer:

  Using libcontainer

  Because containers are spawned in a two step process you will need a binary
  that will be executed as the init process for the container.
  In libcontainer, we use the current binary (/proc/self/exe) to be executed
  as the init process[...]

: OTOH, nsenter: """And package `nsenter` is only imported in `init.go`, so every time the runc
: `init` command is invoked, that C code is run."""


We may found a good reason why everyone is (re)using runC :)

* The nsenter flow

- hook up at the package import time
- use a C helper to do all the real namespace switching dance
- The C helper has to fork() twice to enter the PID namespace correctly
- The C helper takes care of proper synchronization among temporary processes
- Synchronization is a multi-stage process (you need to set up stuff partially in child and partially in parent -e.g. maps)
- State machine to run code in the proper unix process

Let's have a look to the flow - from 10k meters, only the *major* steps

: turns out this flow is designed to workaround a very ancient version of the go runtime
: - https://github.com/opencontainers/runc/blob/master/libcontainer/nsenter/README.md
: goroutines _used_ not to be allowed at init() time:
: - https://groups.google.com/forum/?fromgroups#!topic/golang-dev/pBroPv1EXmU
: - https://groups.google.com/forum/#!topic/golang-nuts/WkwbdXzgPnc
: around golang v1, goroutines were not allowed
: the current go spec "just" ensure sequential ordering
: - https://golang.org/ref/spec#Package_initialization

* nsenter from 10k meters 1/4

.image images/nsenter_stage_a.png 480 _
.caption do nothing if not asked to (reduce side effects as much as possible)

* nsenter from 10k meters 2/4

.image images/nsenter_stage_b.png 480 _
.caption use clone() to be able to specify NS sharing flags (- and also setjmp!)

* nsenter from 10k meters 3/4

.image images/nsenter_stage_c.png _ 800
.caption spawns a child and sets NS (et. al.)

* nsenter from 10k meters 4/4

.image images/nsenter_stage_d.png _ 720
.caption we need another child to actually enter the NS

: code comment in nsexec.c:
: /*
:  * We fork again because of PID namespace, setns(2) or unshare(2) don't
:  * change the PID namespace of the calling process, because doing so
:  * would change the caller's idea of its own PID (as reported by getpid()),
:  * which would break many applications and libraries, so we must fork
:  * to actually enter the new PID namespace.
:  */


* The good solution: just use go >= 1.10

Three fixes merged in go 1.10

- #20676: No new thread will be created from a thread which is currently locked with runtime.LockOSThread.
- #20395: A locked thread will not be re-used to schedule other goroutines if a goroutine did not unlock it before exiting.
- #20458: If a thread was locked multiple times, runtime.UnlockOSThread has to be called equal number of times in order to unlock the thread.

Problem solved:

  // +build go1.10


* Problem really solved?


  func runInsideNS() {
    runtime.LockOSThread()
    defer runtime.UnlockOSThread()

    netns.Set(containerNs)
    defer netns.Set(hostNs)

    go doOtherStuff()  // on which NS am I?

    doStuff()
  }


* Problem indeed solved, if you are careful

Caution!
- the namespace is a *thread* property
- the go scheduler can run gorutines on any available thread

So:
- do not spawn goroutine in the scenario above
- you need to make sure that no packages you use spawn goroutines!

Maybe these two points can be checked by some automated tools in the future?

* wrap up

Switching namespace _still_ require care in go

Go is maturing fast to be used as system language

Some of the complexity hidden in the existing package is being simplified away by the evolution
of the go language.

Still worth reading that code: the steps needed to do the work are still relevant (or the same!)
Well-maintained battle-tested code has worthy lessons embedded

* Q? A!

Questions?

Slides & more @ https://github.com/mojaves/
